#include <torch/extension.h>

#include <ATen/Context.h>
#include <ATen/cuda/CUDAContext.h>

#include <cuda.h>
#include <cuda_runtime.h>
#include <iostream>
#include <vector>
#include <chrono>
#include <string>

//#define DEBUG

#define STRINGIFY2(X) #X
#define STRINGIFY(X) STRINGIFY2(X)


#ifdef DEBUG
#   define TIMER PerfTimer timer = PerfTimer()
#   define TIMER_CHECK(x) timer.check(x) 
#   define DEBUG_PRINT(x) std::cout << STRINGIFY(x) ":" << x << std::endl
#else
#   define TIMER
#   define TIMER_CHECK(x)
#   define DEBUG_PRINT(x)
#endif 

namespace F = torch::nn::functional;
namespace I = torch::indexing;

class PerfTimer {

    cudaStream_t m_stream;
    std::chrono::time_point<std::chrono::system_clock> m_curr;

public:
    
    PerfTimer() {
        m_stream = at::cuda::getCurrentCUDAStream();    
        cudaStreamSynchronize(m_stream);
        m_curr = std::chrono::system_clock::now();
    }

    void check(std::string checkpoint) {
        cudaStreamSynchronize(m_stream);
        auto end = std::chrono::system_clock::now();
        auto elapsed_seconds = std::chrono::duration_cast<std::chrono::microseconds>(end-m_curr);
        std::cout << checkpoint << ": " << elapsed_seconds.count() << " us" << std::endl;
        m_curr = end;
    }
};


__global__ void kernel_sum_mat(
    const float* __restrict__ mat_a,
    const float* __restrict__ mat_b,
    float* __restrict__ mat_out,
    const int n
){
    int idx = blockIdx.x*blockDim.x + threadIdx.x; //global idx
    int stride = blockDim.x*gridDim.x; //block size * block num
    if (idx > n) return;
    
    for (int i=idx; i<n; i+=stride) {
        mat_out[i] = mat_a[i] + mat_b[i];
    }
}


std::vector<torch::Tensor> f_matrix_sum(
    const torch::Tensor mat_a,
    const torch::Tensor mat_b) {

    int n = mat_a.size(0);

    const int _sum_threads = 32; // threads per block
    const int _sum_blocks = (n + _sum_threads - 1) / _sum_threads;

    // create an empty tensor to store the output.
    torch::Tensor mat_out = torch::empty({n}, torch::TensorOptions().dtype(torch::kFloat32).device(torch::kCUDA));

    kernel_sum_mat <<<_sum_blocks, _sum_threads>>> (
            mat_a.data<float>(),
            mat_b.data<float>(),
            mat_out.data<float>(),
            n); 

    return {mat_out};
}

PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
  m.def("cuda_test", &f_matrix_sum, "sum 2 matrix");
}